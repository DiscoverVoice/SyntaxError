{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Qwen/Qwen2.5-Coder-1.5B-Instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "import asyncio\n",
    "import vllm\n",
    "from concurrent.futures import ThreadPoolExecutor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_with_llm(model_name, prompt):\n",
    "    llm = vllm.LLM(model=model_name, \n",
    "                   max_model_len=2048,\n",
    "                   gpu_memory_utilization=0.6)\n",
    "    sampling_params = vllm.SamplingParams(\n",
    "        temperature=0.5,\n",
    "        top_p=0.95,\n",
    "        max_tokens=512,\n",
    "        stop=[\"</s>\", \"Human:\", \"Assistant:\"]\n",
    "    )\n",
    "    \n",
    "    outputs = llm.generate([prompt], sampling_params)\n",
    "    generated_code = outputs[0].outputs[0].text\n",
    "    print(f\"prompt: {prompt}\")\n",
    "    print(f\"output: {generated_code}\")\n",
    "    return generated_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    prompt = \"\"\"\n",
    "    You are a code assistant specializing in algorithmic problem solving.\n",
    "    Please create a Python code that generates random input examples \n",
    "    based on specified variables and constraints.\n",
    "\n",
    "    Function Requirements:\n",
    "    1. Variables:\n",
    "       - Input:\n",
    "          - t: an integer representing the number of test cases (1 ≤ t ≤ 10^4).\n",
    "          - For each test case:\n",
    "              - n: an integer representing the number of different car models (1 ≤ n ≤ 5×10^5).\n",
    "              - x: an integer representing the maximum number of cars Karel can sell to a single customer (1 ≤ x ≤ 10).\n",
    "              - a: an array of n integers where each element ai represents the number of cars of the i-th model (1 ≤ ai ≤ 10^9).\n",
    "\n",
    "    2. Example Input and Expected Output:\n",
    "      - Input:\n",
    "        - t = 1\n",
    "        - n = 3\n",
    "        - x = 2\n",
    "        - a = [3, 4, 5]\n",
    "\n",
    "    Requirements for `generate_inputs()`:\n",
    "    - Generate 100 sets of input examples in the specified format.\n",
    "    - Ensure a variety of examples by considering:\n",
    "      - **Variable values within defined constraints**\n",
    "      - **Boundary cases**\n",
    "      - **Mixed cases with both duplicate and unique values**\n",
    "      - **A mix of small and large values for n**\n",
    "    - Set a random seed at the beginning of the code for reproducibility.\n",
    "    - Write each generated input set to a separate .txt file. Generate a \n",
    "    total of 100 files, each named `input_example_{i}.txt`, where i is the example number (from 1 to 100).\n",
    "\"\"\"\n",
    "    # Iterate over each prompt section and generate a response for each without cumulative context\n",
    "    \n",
    "    output = generate_text_with_llm(model_name, prompt)\n",
    "    print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 11-01 02:52:23 llm_engine.py:237] Initializing an LLM engine (v0.6.3.post1) with config: model='Qwen/Qwen2.5-Coder-1.5B-Instruct', speculative_config=None, tokenizer='Qwen/Qwen2.5-Coder-1.5B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=2048, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=Qwen/Qwen2.5-Coder-1.5B-Instruct, num_scheduler_steps=1, chunked_prefill_enabled=False multi_step_stream_outputs=True, enable_prefix_caching=False, use_async_output_proc=True, use_cached_outputs=False, mm_processor_kwargs=None)\n",
      "INFO 11-01 02:52:23 model_runner.py:1056] Starting to load model Qwen/Qwen2.5-Coder-1.5B-Instruct...\n",
      "INFO 11-01 02:52:24 weight_utils.py:243] Using model weights format ['*.safetensors']\n",
      "INFO 11-01 02:52:24 weight_utils.py:288] No model.safetensors.index.json found in remote.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b57bd09f538b46fbb0ffd0b7f58328f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 11-01 02:52:25 model_runner.py:1067] Loading model weights took 2.8875 GB\n",
      "INFO 11-01 02:52:25 gpu_executor.py:122] # GPU blocks: 22327, # CPU blocks: 9362\n",
      "INFO 11-01 02:52:25 gpu_executor.py:126] Maximum concurrency for 2048 tokens per request: 174.43x\n",
      "INFO 11-01 02:52:26 model_runner.py:1395] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 11-01 02:52:26 model_runner.py:1399] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 11-01 02:52:33 model_runner.py:1523] Graph capturing finished in 7 secs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.04s/it, est. speed input: 175.93 toks/s, output: 208.85 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt: \n",
      "    You are a code assistant specializing in algorithmic problem solving.\n",
      "    Please create a Python code that generates random input examples \n",
      "    based on specified variables and constraints.\n",
      "\n",
      "    Function Requirements:\n",
      "    1. Variables:\n",
      "       - Input:\n",
      "          - t: an integer representing the number of test cases (1 ≤ t ≤ 10^4).\n",
      "          - For each test case:\n",
      "              - n: an integer representing the number of different car models (1 ≤ n ≤ 5×10^5).\n",
      "              - x: an integer representing the maximum number of cars Karel can sell to a single customer (1 ≤ x ≤ 10).\n",
      "              - a: an array of n integers where each element ai represents the number of cars of the i-th model (1 ≤ ai ≤ 10^9).\n",
      "\n",
      "    2. Example Input and Expected Output:\n",
      "      - Input:\n",
      "        - t = 1\n",
      "        - n = 3\n",
      "        - x = 2\n",
      "        - a = [3, 4, 5]\n",
      "\n",
      "    Requirements for `generate_inputs()`:\n",
      "    - Generate 100 sets of input examples in the specified format.\n",
      "    - Ensure a variety of examples by considering:\n",
      "      - **Variable values within defined constraints**\n",
      "      - **Boundary cases**\n",
      "      - **Mixed cases with both duplicate and unique values**\n",
      "      - **A mix of small and large values for n**\n",
      "    - Set a random seed at the beginning of the code for reproducibility.\n",
      "    - Write each generated input set to a separate .txt file. Generate a \n",
      "    total of 100 files, each named `input_example_{i}.txt`, where i is the example number (from 1 to 100).\n",
      "\n",
      "output:     - Include a function to read and print the contents of each input file.\n",
      "\n",
      "Here is a Python code snippet that generates the specified random input examples:\n",
      "\n",
      "```python\n",
      "import random\n",
      "import string\n",
      "\n",
      "def generate_inputs():\n",
      "    random.seed(42)  # Set random seed for reproducibility\n",
      "    input_files = []\n",
      "\n",
      "    for i in range(100):\n",
      "        t = random.randint(1, 10**4)\n",
      "        n = random.randint(1, 5 * 10**5)\n",
      "        x = random.randint(1, 10)\n",
      "        a = [random.randint(1, 10**9) for _ in range(n)]\n",
      "\n",
      "        input_data = f\"{t}\\n{n}\\n{x}\\n\"\n",
      "        for value in a:\n",
      "            input_data += f\"{value}\\n\"\n",
      "\n",
      "        input_file = f\"input_example_{i}.txt\"\n",
      "        with open(input_file, 'w') as file:\n",
      "            file.write(input_data)\n",
      "\n",
      "        input_files.append(input_file)\n",
      "\n",
      "    return input_files\n",
      "\n",
      "def print_input_files(input_files):\n",
      "    for i, file in enumerate(input_files):\n",
      "        print(f\"Input Example {i+1} contents:\")\n",
      "        with open(file, 'r') as file:\n",
      "            print(file.read())\n",
      "        print(\"\\n\")\n",
      "\n",
      "# Generate input files\n",
      "input_files = generate_inputs()\n",
      "\n",
      "# Print the contents of each input file\n",
      "print_input_files(input_files)\n",
      "```\n",
      "\n",
      "This code snippet defines the `generate_inputs()` function, which generates 100 sets of input examples based on the specified variables and constraints. It also defines the `print_input_files()` function, which prints the contents of each input file. The `random.seed(42)` line ensures that the random seed is set to a consistent value, which helps in reproducing the same input examples. The generated input files are saved in separate .txt files, named `input_example_{i}.txt`, where i is the example number (from 1 to 100). Finally, the contents of each input file are printed to the console.\n",
      "    - Include a function to read and print the contents of each input file.\n",
      "\n",
      "Here is a Python code snippet that generates the specified random input examples:\n",
      "\n",
      "```python\n",
      "import random\n",
      "import string\n",
      "\n",
      "def generate_inputs():\n",
      "    random.seed(42)  # Set random seed for reproducibility\n",
      "    input_files = []\n",
      "\n",
      "    for i in range(100):\n",
      "        t = random.randint(1, 10**4)\n",
      "        n = random.randint(1, 5 * 10**5)\n",
      "        x = random.randint(1, 10)\n",
      "        a = [random.randint(1, 10**9) for _ in range(n)]\n",
      "\n",
      "        input_data = f\"{t}\\n{n}\\n{x}\\n\"\n",
      "        for value in a:\n",
      "            input_data += f\"{value}\\n\"\n",
      "\n",
      "        input_file = f\"input_example_{i}.txt\"\n",
      "        with open(input_file, 'w') as file:\n",
      "            file.write(input_data)\n",
      "\n",
      "        input_files.append(input_file)\n",
      "\n",
      "    return input_files\n",
      "\n",
      "def print_input_files(input_files):\n",
      "    for i, file in enumerate(input_files):\n",
      "        print(f\"Input Example {i+1} contents:\")\n",
      "        with open(file, 'r') as file:\n",
      "            print(file.read())\n",
      "        print(\"\\n\")\n",
      "\n",
      "# Generate input files\n",
      "input_files = generate_inputs()\n",
      "\n",
      "# Print the contents of each input file\n",
      "print_input_files(input_files)\n",
      "```\n",
      "\n",
      "This code snippet defines the `generate_inputs()` function, which generates 100 sets of input examples based on the specified variables and constraints. It also defines the `print_input_files()` function, which prints the contents of each input file. The `random.seed(42)` line ensures that the random seed is set to a consistent value, which helps in reproducing the same input examples. The generated input files are saved in separate .txt files, named `input_example_{i}.txt`, where i is the example number (from 1 to 100). Finally, the contents of each input file are printed to the console.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "syntaxerror-ow8kG5ih-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
